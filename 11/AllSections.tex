\documentclass{article}

\usepackage[super]{nth}
\usepackage{amsmath, amssymb}
\usepackage{hyperref}

\setlength{\textwidth}{6.5in}
\setlength{\textheight}{8in}
\setlength{\oddsidemargin}{0in}
\setlength{\evensidemargin}{0in}

\setlength{\parskip}{2ex}
\setlength{\parindent}{0in}

\begin{document}

\section*{Chapter 1}

\begin{enumerate}

    \item Individuals of a Study
    
    \item The Variable of a study
        \begin{itemize}
        \item What is being \textbf{measured}
        \item Qualitative vs. Quantitative
        \item Emphasize the difference and point out it goes beyond ``numbers" vs. words...
        \end{itemize}
        
    \item Parameter vs. Statistic
    
    \item Levels of Measurement
    
        \begin{itemize}
        
            \item Nominal
            \item Ordinal
            \item Interval
            \item Ratio
            \item A good thing to point out is that Ratio levels of measurement are usually are not negative valued because of the existence of this ``absolute zero"
            
        \end{itemize}
        
    \item Descriptive vs. Inferential Statistics
    
    \item Sampling Techniques
    
        \begin{itemize}
        \item Simple Random -- Each individual is equally likely to be selected in the sample
        \item Cluster -- Entire, randomly selected groups are included
        \item Stratified -- Random samples from every group is included
        \item Systematic -- Choosing names from a list in a systematic fashion
        \end{itemize}
        
    \item Experimental Design
    
        \begin{itemize}
        \item Placebo
        \item Treatment vs. control
        \item Double blind
        \end{itemize}
        
\end{enumerate}
    
        
        
\section*{2.1 Frequency Distributions, Histograms, Etc.}

\begin{enumerate}

    \item Describe how frequency tables organize data into classes and then lists the numbers of data points in each class
    
    \item Describe the procedure to finding class limits/widths for {\bf integer} valued data
    
        \begin{enumerate}
        
            \item $\displaystyle{class\;width = \frac{largest\;data\;value - smallest\;data\;value}{number of class limits}}$
            
            \item Then {\bf increase} this to the next integer, even if the above computation yields an integer. For example, $=4.4\rightarrow 5$ and $=7 \rightarrow 8$.
            
        \end{enumerate}
        
    \item How to compute limits,boundaries/midpoints of classes.
    
    \item If the data is decimals, then multiply by an appropriate power of 10 to convert all data points to integers. Proceed as above. Then divide class limits, boundaries and midpoints by said power of 10.
    
    \item Histograms
    
    \item Relative frequency in tables and histograms
    
    \item Shapes of distributions
    
        \begin{itemize}
        
            \item Left-skewed data means the long-tail is on the {\bf left side} of the median
            
            \item Right-skewed data means the long-tail is on the {\bf right side} of the median
            
        \end{itemize}
    
    \item Cumulative frequency tables
    
    \item Ogive (pronounced oh-jive and rhymes with hive)
    
\end{enumerate}

\section*{2.2 Types of Graphs}

\begin{enumerate}

    \item Bar Graphs
    
    \item Circle Graphs (commonly known as Pie Charts)
    
        \begin{itemize}
        
            \item Only used for parts of a whole
            
        \end{itemize}
        
    \item Time series data/graphs
    
    \item Pareto graphs
    
        \begin{itemize}
        
            \item A special type of bar graph/histogram
            
            \item The rectangles are arranged from most frequent to least frequent
            
            \item Not necessarily left-to-right; can be arranged vertically
            
        \end{itemize}
        
\end{enumerate}

\section*{2.3 Stem and Leaf Displays}

\begin{enumerate}

    \item Pay attention to the {\bf key}.
    
    \item Note the leaves need not be ordered
    
    \item Can also be back-to-back to show data tables for two different groups.
    
\end{enumerate}

\section*{3.1  Measures of Central Tendency: Mode, Median, Mode}

\begin{enumerate}

    \item Mode: The most frequent data value
    
    \item Median: The ``middle" data value
        
        \begin{itemize} 
        
            \item Explain how to compute this. Use the formula $\frac{n+1}{2}$ as a guide.
            
            \item Be sure to explain the difference when there is an even or odd number of data points.
            
        \end{itemize}
        
    \item Mean: The arithmetic average.
    
        \begin{itemize}
            
            \item For a {\bf sample}, $\bar{x} = \frac{\sum x}{n}$ and a {\bf population}, $\mu = \frac{\sum x}{N}.$
            
            \item State our convention of using Greek letters to denote parameters and Latin letters (our usual letters) for statistics. Also, N is for a population size and n is for a sample size.
            
        \end{itemize}
    
    \item Weighted Average
    
        \begin{itemize}
        
            \item Be sure to mention that how ``weights" can be anything and it is not necessary for them to be percentages.
            
            \item State how their grade for this class will be computed by a weighted average.
            
            \begin{center}
            \begin{tabular}{ll}
            Participation & 5\% \\
            Reading Assignments & 10\% \\
            Chapter Reviews & 10\% \\
            Quizzes & 15\% \\
            Midterm 1 & 15\% \\
            Midterm 2 & 15\% \\
            Final Exam & 20\% \\
            \end{tabular}
            \end{center}
            
            \item Also take this time to mention how the final exam score could replace a worse midterm score.
            
        \end{itemize}
        
\end{enumerate}
        
        

\section*{3.2  Measures of Variation}

\begin{enumerate}

    \item Give two data sets like

        $$\{10, 9, 9, 8, 8, 8, 7, 7, 7, 7, 6, 6, 6, 5, 5, 4\}$$

        $$\{10, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 4\}$$
    \begin{itemize}
    
        \item Ask the students ``Which data set is more varied?" Explain how standard deviation/variance measures this property. 
        
        \item Range: $highest-lowest$. Show both data sets have the same range.
        
    \end{itemize}


    \item Formula for Variance/Standard Deviation
    
    $$\sigma^2 = \frac{ \sum (x-\mu)^2}{N}$$
    
    $$s^2 = \frac{ \sum (x-\bar{x})^2}{n-1}$$
    
        \begin{itemize}
        
            \item As with means, be sure to point out the difference between a population variance and sample standard deviation. Students often get the two mixed up.
            
            \item Always emphasize which one should be computing/using in formulas and discussions.
            
            \item Explain that the second data set has a smaller standard deviation than the first.
            
            \item Mention that we will not have to compute by hand, so no need to ponder the computational formulas.

        \end{itemize}

    \item Coefficient of Variation: Describes standard deviation as a percentage of the mean.
    
        \begin{itemize}
        
            \item Perhaps note that for $\{100, 70, 70, 70,\ldots,70, 40\}$, the standard deviation and mean is ten times than for the data set above; but are they really that different?
            
        \end{itemize}

    \item Chebyshev's Theorem: $1-\frac{1}{k^2}$ of data falls within $\mu\pm k \sigma$ for $k\geq 1$.
        
        \begin{itemize}
        
        \item Students will have difficulty understanding this lemma. A good idea state the following results:
        
        $$\geq 75\%\;\mbox{within} \mu \pm 2\sigma$$
        $$\geq 88.9\%\;\mbox{within} \mu \pm 3\sigma$$
        $$\geq 93.8\%\;\mbox{within} \mu \pm 4\sigma$$
        
        \item Expect questions about this on Monday.
        
        \item Note that for the mound-shape symmetric distributions, the result is much stronger. We will see that later.

        \end{itemize}

\end{enumerate}

\section*{3.3 Percentiles and Quartiles}

\begin{enumerate}

    \item Definition of a percentile

    \item Box-and-whisker
    
        \begin{itemize}
        
        \item The two ends and middle lines for the box represent quartile marks.
        
        \end{itemize}

    \item This concept is valuable in future sections.

    \item Specifically mention quartiles as \nth{25}, \nth{50}, \nth{75}-percentiles (I wouldn’t mention it now, but be prepared for next class to clarify that this textbook finds Q1 as the median of data BELOW Q2 (not including Q2).  Not all textbooks agree and there are at least 9 different and sensible definitions for this values for discrete data.)

    \item Visual display of LOWEST, Q1, Q2, Q3, HIGHEST (also know as the five-number summary)
    
    \item Be sure to emphasize that {\bf all} statistics in this chapter is handled by \texttt{1-VAR STATS} on the calculator.
    
\end{enumerate}

\section*{4.1 What is Probability?}

\begin{enumerate}

    \item Summary box on page 137 pretty much sums up the key points.

    \item A statistical experiment is any random activity that results in a definite outcome. Give examples like drawing cards, rolling dice, spinning the big wheel on ``The Price is Right", etc.
    
        \begin{itemize}
            
            \item Sample space, simple event, event. Give an example of these terms with dice rolling.
            
            \item Probability will always be a value between 0 and 1 (inclusive). State when an event has probability 0 or 1.
            
            \item I don’t care if students use fractions, decimals, or percentages.
            
        \end{itemize}
        
    \item Notation
    
        \begin{itemize}
            
            \item $P(A)$.
            
            \item $P(A^c)$.
            
            \item $P(A)+P(A^c)=1$.
            
        \end{itemize}
        
    \item Computed by
    
        \begin{itemize}
        
            \item Theoretical design and counting simple events.  Be sure to emphasize formula of $$P(A)=\frac{\textnormal{Number of outcomes in } A}{\textnormal{Number of all possible outcomes.}}.$$
            
            
            \item Empirical data and relative frequencies. Include the statement of the law of large numbers. Also emphasize that these methods will always \textbf{approximate} the probability of an event and may not ever get with total accuracy.
            
        \end{itemize}
        
    \item Why is probability relevant to statistics?
    
        \begin{itemize}
        
            \item Probability is about assigning a likelihood to a particular outcome of an unknown experiment. The most relevant situation is assigning probabilities to sampling from a \textbf{known} population.
            
            \item Statistics is about using the results of sampling to infer information about an \textbf{unknown} population.
            
        \end{itemize}
    
\end{enumerate}

\newpage

\section*{4.2 Some Probability Rules---Compound Events}

\begin{enumerate}

    \item There are some formulas in this section, but often I try to de-emphasize them in trade for ``careful counting".
    
    \item The concept of conditional probability is always tricky for students. Carefully explain the concept with emphasis that for $P(A | B)$, the event $B$ is \textbf{known} to have happened.
    
    \item Note the two key terms
    
        \begin{itemize}
        
            \item Mutually exclusive
            
            \item Independent
            
        \end{itemize}
        
    \item Be sure to explain the difference between to conjunctions \textbf{or} and \textbf{and}. The use of a Venn diagram will be of help.
    
    \item Describe a standard deck of 52 cards.
    
        \begin{itemize}
        
            \item Show how to compute $P(\mbox{Ace})$, $P(\mbox{Heart})$, \\ $P(\mbox{Ace or Heart}),$ $P(\mbox{Ace and Heart})$, $P(\mbox{Ace} | \mbox{Heart})$.
            
        \end{itemize}
        
    \item Provide a contingency table and compute some probabilities with it. 
    
    \renewcommand{\arraystretch}{1.2}
    
	\begin{center}
	
	\begin{tabular}{ccccc}
	& \multicolumn{3}{c}{\textbf{Political Affiliation}} \\ \cline{2-4}
	{\textbf{ Employee Type}} & Democrat (D) & Republican (R) & Independent (I) & Row Total\\	\hline
	Executive (E) \hfill& 5 & 34 & 9 & 48 \\
	
	\begin{tabular}{@{}r@{}} Production \\ Worker \end{tabular} (PW) \hfill & 63 & 21 & 8 & 92 \\
	\hline
	Column Total \hfill  & 68 & 55 & 17 & 140 \\
	\end{tabular}
	\end{center}
	
	    \begin{itemize}
	    
	        \item $P(D)$ and $P(E)$.
	        
	        \item $P(D \mbox{ and } E)$.
	        
	        \item $P(D | E)$.
	        
	   \end{itemize}
	   
\end{enumerate}

\section*{5.1 Discrete Probability Distributions}

\begin{enumerate}

    \item Refer to the ``sum of two dice" exercise as an example of such a probability distribution.
    
    \item Discuss {\bf expected value} and {\bf standard deviation} of a probability distribution. 
    
        \begin{itemize}
        
            \item Point how the formulas are like the formulas we already know for mean, variance and standard deviation but also what makes them different.
            
            $$E(X) = \mu = \sum xP(x)$$
            
            $$Var(x) = \sum (x-\mu)^2p(x) = \sum x^2P(x) - \mu^2 = E(X^2) - E(x)^2.$$
            
            \item These last two formulas for variance are not in the book, but are easier to use if someone were to compute them by hand.
            
            \item Note that 1-Var Stats can still get the job done for us, like a weighted average or frequency table. Use the probabilities in the ``frequency table".
            
        \end{itemize}
        
    \item As far as the linear combination stuff, we don’t do much with this topic. I plan to skip this, since the Excel discussion will be of more value. Mention it and tell them to read it carefully.

\end{enumerate}

\section*{5.2 \& 5.3 Binomial Distribution}

\begin{enumerate}

    \item  Describe the features of a binomial experiment. Begin with the example of flipping a coin 10 times in a row and counting the number of heads (which we consider a success).
    
        \begin{itemize}
        
            \item A \textbf{fixed number} $n$  of trials.
            
            \item Each trial is independent of all others.
            
            \item Each trial has two outcomes: a success (with probability $p$) and failure (with probability $1-p=q$).
            
            \item The goal is to count the number of successes $r$ in $n$ trials. 
            
        \end{itemize}
        
    \item Present the formula, $P(X=r) = \binom{n}{r}p^r(1-p)^{n-r} = \binom{n}{r}p^r q^{n-r}.$
    
         Because we didn’t cover Section 4.3 about counting, the reference to $C_{n,r}=\binom{n}{r}$ will be to state that it is the number of ways that the $r$ successes could have fallen in those $n$ trials.
         
    \item Note that the TI calcs have binompdf and binomcdf. Refer them to the screencasts if they don’t know how to use those functions already, but make a point to review them right before the worksheet next Wednesday.
    
     Specifically (on Wednesday) review the syntax and application of \texttt{binompdf(n,p,r)} which computes the probability of EXACTLY r successes out of n trials, $P(X=r)$, while \texttt{binomcdf(n,p,r)} computes the probability of at most r success out of n trials, $P(X\leq r)$.  Discuss how we can compute the probability of at least $r$ successes (say) when neither function is explicitly designed to do that by using compliments.
     
    \item A quick note of the formulas for expected value and standard deviation for a binomially distributed random variable.  They won’t use 1-Var Stats, most likely, because the formulas are so much simpler.
    $$E(X) = np$$
    $$Var(x) = npq=np(1-p)$$
    
\end{enumerate}

\section*{Excel Intro}

    \begin{enumerate}
    
        \item Use the ``Excel for Friday" file.  There is a Highlights sheet that has some key ideas to cover as a point of reference for you to plan, a DATASHEET sheet with the some data set up to demonstrate to computations, and an Answer Key sheet.  (If you aren’t sure what to do, practice by referring to the ``Answer Key".)
        
        \item Also, tell them to download the Excel Sheet in D2L \textbf{before} class on Friday if they plan to bring their laptops. I found it is more beneficial for them if they can follow along on their own.
        
        \item The idea is to give a student who has little or no experience with Excel a quick look at how to enter a basic formula or function to complete a computation on the DATASHEET page.
        
        \item The dataset is small so after using the function to compute the result, a quick visual verification can be done. The dataset for the project is much larger and hand verification is unrealistic.
        
        \item Also, another item to stress as you do the demo is the idea of robustness, which is accomplished through cell referencing. So, for example, when you compute \% Heads, you will use the cell reference as \texttt{=A3/B1} rather than \textbf{hard coding} in as \texttt{=31/50}.  That way, WHEN new data is entered to overwrite the original data, the \% will update automatically.
        
            \begin{itemize}
            
                \item Note that part of the grading process will be to actually paste a new set of data over their original data set to see if the objects they created update and adjust to the new data set. So, it is important that they understand this expectation.
                
                \item As an example, after having coded in the robust functions, like =MIN(A3:A22) to see LOW value, go into the data and overwrite the low value with a LOWER one so that the students can see the outcome for the formula change.
                
            \end{itemize}
            
    \end{enumerate}
    

I am happy to provide a brief tutorial on Excel, if you need it.  Just let me know and we will figure out a time to meet.

\newpage

%Friday before Exam 1
The primary goal here is to give the students an outline of material to review for the Midterm on Wednesday. Since they have a quiz this day, I will not have enough time to fill in details. I plan to write this out and if someone has a specific question on something, I will then go into detail.

\begin{enumerate}

    \item Remind them that Chapter Review (Chapter 4) on WebAssign is due tonight AND although Chapter Review (Chapter 5) is not due until 2/19, the midterm on 2/17 covers Chapter 5 material, so it will be to their advantage to complete it before the midterm.

    \item As far as resources during the midterm:
        
        \begin{itemize}
        
            \item Calculator (with NO internet access) When a calculator function is used, \textbf{work required is to write the function and input values used.} I do not supply calculators. If they show up without one on exam day, then they will suffer. Phones will not be allowed as a substitute.
            
            \item Formula sheet: A copy of the ``Frequently Used Formulas" for Chapter 1-5 (as shown in the back cover of the textbook; they can even see that in the online textbook).
            
        \end{itemize}
        
    \item Resources for more practice problems:
        
        \begin{itemize}
        
            \item WebAssign problems with ``Practice Another Version".  Not all problems are programmed with this option in WebAssign.
            
            \item Odd-numbered problems from the textbook where the correct answer can be checked in the back of the textbook (even the online version).
            
        \end{itemize}
    
    \item The worksheet on Monday will be a ``mini-midterm" useful for review. Homework for Monday is to start studying for the midterm.
    
\end{enumerate}


\section*{Outline of content by Chapter}

\begin{enumerate}

    \item CHAPTER 1
    
        \begin{enumerate}
        
            \item Vocabulary terms: Individual, population, quantitative variable, qualitative variable, statistic, parameter, descriptive statistics, inferential statistics
            
            \item Levels of measurement: Nominal, ordinal, interval, ratio
            
            \item Sampling techniques: Random, stratified, systematic, cluster, convenience, multi-stage
            
            \item Basics of experimental design: Observational study vs experiment, Control group, placebo and placebo effect
            
        \end{enumerate}
        
    \item CHAPTER 2
    
        \begin{enumerate}
        
            \item Displaying data: Frequency tables 
            
            \item Class limits, class boundaries, class width, midpoint, relative frequency, cumulative frequency
            
            \item Histograms \& ogives
            
            \item Symmetry and skewness of histogram
            
            \item Graphs: Bar graph, Pareto chart, Circle (pie) graph, Time-Series graph
            
            \item Stem-and-Leaf displays
            
        \end{enumerate}
        
    \item CHAPTER 3 : \texttt{1-Var Stats}
    
        \begin{enumerate}
        
            \item Central tendencies: Mean, median, mode, trimmed mean, weighted mean
            
            \item Variation
            
                \begin{itemize}
                    
                    \item Range, variance, standard deviation (statistic and parameter)
                    
                    \item Coefficient of variation
                    
                    \item Chebyshev’s Theorem
                
                \end{itemize}
                
            \item Percentiles and Box-and-Whisker
            
            \item Quartiles, IQR, 5-number summary
            
        \end{enumerate}
        
    \item CHAPTER 4
    
        \begin{enumerate}
        
            \item Elementary probability theory
            
                \begin{itemize}
                
                    \item Sample space, notation $P(A)$, $P(A^c)$, equally likely outcomes, using relative frequency
                    
                    \item $P(A \mbox{ or } B)$, $P(A \mbox{ and } B)$, $P(A|B)$, independence, mutual exclusivity
                    
                \end{itemize}
                
        \end{enumerate}
        
    \item CHAPTER 5 
    
        \begin{enumerate}
        
            \item Discrete probability distribution
            
            \item Valid probability distribution, mean (expected value), standard deviation
            
            \item Binomial probabilities
            
                \begin{itemize}
                
                    \item Criteria of a binomial experiment
                    
                    \item Probability of exactly r successes, at most r successes, at least r successes, fewer than r successes, more than r successes, etc.
                    
                \end{itemize}
        \end{enumerate}
        
\end{enumerate}

\newpage

%After Midterm 1 Friday

I hope to have my Midterms graded by Friday. So, I may start with reviewing any commonly missed problems, if there seems to be some obvious choices for that discussion. Otherwise, I do NOT intend to go over the midterm in class; students will have to seek out help in office hours on an individual basis.
 
\section*{6.1 Normal Probability Distribution}

    \begin{enumerate}
    
        \item Ask the class about the difference between a discrete random variable and a continuous random variable.
        
        \item Ask the class what the sum of the probabilities in a discrete probability distribution must equal.
        
        \item Introduce the normal distribution
        
            \begin{itemize}
            
                \item Unimodal, symmetric, approaching x-axis, area under curve is 1.  
                
                \item Draw a picture and label the mean. As note the distance between the maximum and inflection points is equal to the standard deviation, which is 1.
                
                \item I see no need to write down the density function, as it will likely be met with vacant stares.
                
                \item Point out that the students should pay close attention to the Empirical Rule in the reading and to note its connection to Chebyshev’s Theorem.
            
            \end{itemize}
            
        \item Introduce the concept of a Control Chart.
        
            \begin{itemize}
            
                \item Using a mean and standard deviation computed from historical data or industry standards, a control chart is a mechanism to determine if the variable is in statistical control. This chart is essentially following the expected distribution from the mean and standard deviation.
                
                \item There are 3 ``out-of-control" signals. Make note of them from the reading.
                
                    \begin{itemize}
                    
                        \item One reading beyond $3\sigma$ of average.
                        
                        \item 9 \textbf{consecutive} on one side of average.
                        
                        \item 2 of 3 points beyond $2\sigma$ of average.
                        
                    \end{itemize}
                    
            \end{itemize}
            
    \end{enumerate}

\newpage

\section*{Sections 6.2 \& 6.3 Computing Area under Normal Curves}

    \begin{enumerate}
    
        \item In these sections, they will see examples and applications of computing the area under the normal curve above, below, and between specified points.
        
            \begin{itemize}
            
                \item \texttt{NORMALCDF} (under the \texttt{DISTR} menu) will be their friend here.  Somewhat similar in concept to \texttt{BINOMCDF}, it is more flexible with the ability to accept both lower and upper bounds.
                
                \item If they have no lower (or upper bound) for a probability question, have them use \texttt{1E99} for $\infty$ and \texttt{-1E99} for $-\infty$. 
                
                \item The book will show them methods using a table. Those methods are NOT necessary, if they have the calculator. If they desire, tables are to be made available for quizzes, exams and the final.
                
            \end{itemize}
            
        \item The $z$-value (or $z$-score) of a data value $x$ gives the number of standard deviations between the data value and the mean.
        
        \item When the variable $z$ is used, the assumption is that mean = 0 and standard deviation = 1.
        
        \item When the variable $x$ (or any other variable for that matter) is used, we will need to be provided the information on the values of the mean and standard deviation.
        
        \item EITHER $z$- or $x$-information can be entered into the \texttt{NORMALCDF} function.
        
        \item Another function that will be useful is \texttt{INVNORM} (also under \texttt{DISTR}). This is another somewhat restricted function in that it can \textbf{only be applied to a LEFT-TAIL area}.
        
        \item The information about ``checking for normality" is not something that we will assess in this course.  That is not to say that it is worthless, it is just not something that we will explore in this class.
        
    \end{enumerate}
    
\begin{enumerate}

\item The content of 6.4 and 6.5 are really the heart of what makes almost all the rest of the material in the class work. So, the big picture of what is happening is valuable. 

\item We are focusing on the normal distribution. Review the shape, mean and standard deviation of this distribution. Even though the population we inquire about may not be normally distributed, this distribution is none-the-less important.

\item If we have a random sample from a population, we can certainly compute the mean of that sample, but how well can we expect that sample mean to represent the population mean? 

\end{enumerate}

\section*{6.4 \& 6.5 Sampling Distributions and the Central Limit Theorem}

\begin{enumerate}

\item If we were able to take every possible random sample of a specified size $n$ from a population and compute the sample mean for each of those samples, what would that distribution of sample means look like?

\item The Central Limit Theorem tells us that we can expect that (with certain restrictions) the distribution is normal. This is a pretty profound and powerful result. No matter how scattered the population itself is, with some proper guidelines, we can expect that the sample means to be well behaved.

\item Because of this, we can determine the probability of finding a sample with a specific mean (assuming we know the population mean). This is very important as it is the cornerstone of why confidence intervals and hypothesis testing are sound reasoning.

\item The middle (mean) of that distribution of sample means is equal to the population mean itself. So, although there are some sample means that lie far off in the tails of the distribution, they aren't very likely.

\item Further, the standard deviation of that distribution of sample means is equal to the population standard deviation divided by the square root of the sample size. So this implies that the larger the sample size, the smaller the spread of the sample means, which should make sense. The larger the sample size, the more likely it represents the population well.

\end{enumerate}

\section*{Confidence Intervals}

When we can't collect a measurement for every member of a population, how can we determine a population mean?

\begin{enumerate}

    \item Without a full set of population data, we can never be 100\% certain that we know the population mean, but with certain restrictions applied, we can use the data from a random sample to estimate a population parameter.

    \item Even with a large random sample, the value of the sample mean is usually not exactly equal to the population mean. But, according to the Central Limit Theorem, we can have some expectations on how likely it is that the sample mean falls within a certain interval around the population mean. A confidence interval is an interpretation of precisely this application.

    \item What criterion is required to apply the Central Limit Theorem?

    \item The idea is that we start with a sample statistic (called a point estimate). We then create a margin of error around that point estimate which yields an interval of values that is asserted as one that contains the population parameter (at least with some high level of, but not 100\%, certainty)
    
    \begin{enumerate}
    
        \item So, this looks like (point -- error, point + error) or a guess $\pm$error.
        
        \item The size of the error depends on what level of certainty we want to assert.
        
        \item The most prevalent example of a confidence interval are during elections and predicting election results.
        
    \end{enumerate}
    
    \item Keep in mind that although we will be asserting that we have an interval that contains the population parameter, there is no indication where within the interval we expect it to lie.
    
\end{enumerate}

\section*{7.1 Estimating $\mu$ when $\sigma$ is known}

\begin{enumerate}

    \item The first look at confidence intervals assumes that we know $\sigma$.  (This might seem a bit contrived, because why would we know $\sigma$ if we don’t know $\mu$.)
    
    \item The TI \texttt{Z-INTERVAL} function will compute the confidence interval, either by entering the actual list of sample data or by entering the sample mean. For that reason some of the details of the formulation developed in the reading are not so critical, but understanding what the function does and how to interpret the result is critical.
    
    \item When reading, pay special attention to
    
        \begin{itemize}
        
            \item The formula for E in this case, as it should make sense why this is the correct formula.
            
            \item The definition of $z_c$, as this should also be something that you already know how to compute.
            
            \item The interpretation of a confidence interval, as it is easy to misinterpret what the interval found means.
            
        \end{itemize}
        
\end{enumerate}

\section*{7.2 Estimating $\mu$ when $\sigma$ is unknown}

\begin{enumerate}

    \item In this case, a seemingly more common case, we don’t know $\sigma$. So, we must estimate the value of $\sigma$ too. This translates into a slightly larger margin of error to compensate for the potential error in our guess of $\sigma$.
    
    \item Rather than the standard normal distribution, we use the Student's $t$-distributions. There is a slightly different distribution for each sample size, but they are all bell-shaped.  As $n$ gets larger, the $t$-distributions approach the standard normal distribution.
    
    \item The formulation and interpretation of a confidence interval in this case is very similar to that when $\sigma$ is known, just the distributions from which the critical values are determined has changed.
    
    \item The \texttt{T-INTERVAL} function the TI can do the work for us.
    
    \item When reading, pay special attention to
    
        \begin{itemize}
        
            \item The formula for E (which should look VERY similar to that from Section 7.1).
            
            \item The formula for degrees of freedom.
            
        \end{itemize}
        
    \item If your calculator does not already have an \texttt{InvT} function, there is a screencast available about how to create a program in your calculator that does the job.
    
\end{enumerate}

\section*{Internet Visual for Confidence Intervals}

\begin{enumerate}

    \item Start with an overview of what this whole confidence interval and confidence level thing is all about. This applet could be effective in confirming what idea of the c-level, also as a way to compare how the size of the interval changes with changes to the variables.
    
    \item The website is \url{http://www.rossmanchance.com/applets/ConfSim.html}
    
    \item Start with Means, Normal, z with $\sigma$.
    
        \begin{itemize}
        
            \item Show 1 sample
            
            \item Show 10 samples
            
            \item Show 100 samples, maybe a few times to show how the number of ``good" confidence intervals can vary.
            
            \item Change Conf level
            
            \item Change $n$
            
        \end{itemize}
        
    \item Reset and look at Means, Normal, $t$. Note how they can have different lengths. (this is sometimes subtle)  Why?
    
\end{enumerate}

\section*{Section 7.3 Confidence Interval for a Proportion}

\begin{enumerate}

    \item This time, rather than a mean, we are estimating a population proportion, like ``What percentage of all college students change their major at least once in their first four years?"  which is different than ``What is the average number of times a college student changes their major within their first four years?"
    
    \item The calculator function is \texttt{1-PropZInt}.
    
    \item In the reading watch out for
    
        \begin{itemize}
        
            \item The requirement on the sample size, it is more complicated than just $n \geq 30$.
            
            \item The formula for E.
            
            \item The formulas for finding sample size.
            
            \item Interpreting poll results.
            
        \end{itemize}
        
\end{enumerate}

\newpage

\section*{Section 7.4 Confidence Intervals for Differences}

\begin{enumerate}

    \item As our last look at confidence intervals, we look at differences (between two means or between two proportions), as a way to tell if two populations are different.
    
    \item This section refers only to independent samples, but check out the reading for the definitions as it will matter later (when we do tests).
    
    \item \texttt{2-SampZInt}, \texttt{2-SampTInt}, and \texttt{2-PropZInt} are the calculator functions.
    
    \item In the reading watch out for
    
        \begin{itemize}
        
            \item The degrees of freedom for Tint
            
            \item The criteria on sample size (it is again different for $p$ than for $\mu$).
            
            \item The interpretation of the confidence interval
                
            \begin{itemize}
                
                \item When the interval contains only negative values
                
                \item When the interval contains only positive values
                
                \item When the interval contains both positive and negative values.
                
            \end{itemize}
            
        \end{itemize}
        
\end{enumerate}


\section*{Hypothesis Testing}

In Chapter 7, we estimated the value of population parameters (mean and proportion) using confidence intervals. Another method of statistical inference is to make decisions concerning the value of a population parameter, which we do in Chapter 8 with hypothesis testing.

\begin{enumerate}

  \item Suppose that you roll a regular six-sided die 600 times. About how many times would you expect to see a 4 rolled within those 600?
    
    \begin{enumerate}
    
      \item If you saw 105 rolls that were 4, would this be surprising\ldots enough to question the fairness of the die?

      \item What if you saw 595 rolls that were 4, would this be surprising\ldots enough to question the fairness of the die?

      \item Where would you draw the line between ``not so surprising" and ``surprising"?
      
    \end{enumerate}
    
  \item The basic idea in hypothesis testing is to start with an assumption of what ''should" happen and to draw a line on what extreme outcomes would be ``surprising". If the random sample indicates a ''surprising" result, we have evidence to abandon our assumption\ldots if the ransom sample indicates a ``not so surprising" result, we do not have adequate evidence to abandon our assumption and we must stick with it.
  
  \item Note, as with the case of the rolls of the die, the result of the random sample may be very ``surprising" (595 of our 600 rolls were 4), but it will never serve as PROOF that our assumption is wrong (as it's possible that this 595/600 happens with a completely fair die).
  
\end{enumerate}

\section*{8.1 Introduction to Statistical Tests}

\begin{enumerate}

  \item This section introduces the language and formalizes the concepts of ``drawing a line" and interpreting the results of the test.
  
  \item When reading, pays close attention to
  
    \begin{enumerate}
    
      \item The notation and definition/usage of the null hypothesis and the alternate hypothesis. 
      
      \item How we categorize the test as right-tailed, left-tailed, or two-tailed.
      
      \item What the P-value measures and how it is used to draw the conclusion of the test.
      
      \item The usage and meaning of the conventional language of ``Reject $H_0$" and ``Fail to Reject $H_0$".
      
    \end{enumerate}
    
  \item I plan to save the discussion of types of errors until Monday when they should have a slightly better sense of what this is all about.

\end{enumerate}

\newpage

\section*{8.2 Testing the Mean}

\begin{enumerate}

  \item The calculator functions that will be useful are \texttt{Z-Test} and \texttt{T-Test}. Like \texttt{Z-Interval} and \texttt{T-Interval}, one is used with $\sigma$ is known and the other when $\sigma$ is unknown.
  
  \item They may find the ``critical regions" method helpful in solidifying the concepts of hypothesis testing, but they will be required to compute and interpret P-values as well. So, this ``critical regions" method should be considered a secondary method.
  
\end{enumerate}

\section*{8.3 Testing the Proportion}

The calculator function that will be useful is \texttt{1-PropZTest}.

\section*{8.4 Paired Data}

\begin{enumerate}

    \item A discussion of dependent (paired) versus independent data will need to be had.  We treat paired data quite differently than independent data.
    
    \item A good guideline is the following: If you implement two distinct processes on \textbf{the same group} of individuals, then the data is paired.
    
    \item When the data can be paired, the null hypothesis is always that the mean of the differences is 0 (there is no difference).
    
    \item They will need to created a ``new" data set that is the list of differences of the pairs. Then use T-Test to complete the test. By typing $L_1 - L_2$ in the label of the stats editor will generate a difference column.
    
\end{enumerate}

\section*{8.5 Independent Populations}

\begin{enumerate}

    \item Here the null hypothesis is always that the difference of the means (or proportions) is 0 (there is no difference).
    
    \item The \texttt{2-SampZTest}, \texttt{2-SampTTest}, and \texttt{2-PropZTest} are the key calculator functions.
    
    \item Computations are easy with the calculator\ldots reading and deciphering which function does the job for a specific problem is the tough part.
    
\end{enumerate}

\newpage

\section*{Project 2}

\begin{enumerate}

    \item I think that simply stepping through the R Tutorial sheet (or similar exercises) is a good demo.
    
    \item Please announce that there are screencasts in D2L to help show them some of the key functions.
    
    \item It is the workspace (.RData) file that they need to submit. Not their code (.r file), not a picture of their code or a text version of their code\ldots we don’t need to see their code\ldots just the workspace containing the objects created from their code.
    
    \item A computer will be grading their workspace objects. This means that all required objects must be named exactly as written in the project or the grader will not see it. Note that extra objects will simply be ignored, so they can have MORE than what is required with no penalty. But changes in case, transposition of letters, or extraneous symbols in a required object’s name will appear to the grader as if the object simply does not exist. Partial credit may be possible on some objects, but NOT as a result of spelling/typing errors in the object name.
    
    \item Items 2-6 on the worksheet refer to values of objects in their workspace. To earn full credit on these items, the values on the worksheet must match the values in the workspace. Further, these particular objects will be randomly generated when the code is executed. So, rerunning their code can/will change the values of the workspace objects. Therefore, they should not attempt to complete those worksheet items until their workspace is finalized!!
    
\end{enumerate}

\newpage

%Friday before Exam 2

The primary goal here is to give the students an outline of material to review for the Midterm on Wednesday. Since they have a quiz this day, I will not have enough time to fill in details. I plan to write this out and if someone has a specific question on something, I will then go into detail.

\begin{enumerate}

    \item Remind them that although Chapter Review (Chapter 8) is not due until 4/15, the midterm on 4/13 covers Chapter 8 material, so it will be to their advantage to complete it before the midterm.

    \item As far as resources during the midterm:
        
        \begin{itemize}
        
            \item Calculator (with NO internet access) When a calculator function is used, \textbf{work required is to write the function and input values used.} I do not supply calculators. If they show up without one on exam day, then they will suffer. Phones will not be allowed as a substitute.
            
            \item Formula sheet: A copy of the ``Frequently Used Formulas" for Chapter 1-8 (as shown in the back cover of the textbook; they can even see that in the online textbook).
            
            \item The ``Calculator Functions Syntax" sheet on D2L. This just states the necessary parameters for each function with no explanation of what they mean.
            
        \end{itemize}
        
    \item Resources for more practice problems:
        
        \begin{itemize}
        
            \item WebAssign problems with ``Practice Another Version".  Not all problems are programmed with this option in WebAssign.
            
            \item Odd-numbered problems from the textbook where the correct answer can be checked in the back of the textbook (even the online version).
            
        \end{itemize}
    
    \item The worksheet on Monday will be a ``mini-midterm" useful for review. Homework for Monday is to start studying for the midterm.
    
\end{enumerate}


\section*{Outline of content by Chapter}

\begin{enumerate}

    \item CHAPTER 6: Normal Curves and Sampling Distributions
    
        \begin{enumerate}
        
        \item Properties of Normal distribution
        
        \item Empirical Rule: Approximation of how much area is between $\mu \pm k\sigma$ for $k=1,2,3$.
        
        \item Control Charts, we have 3 ``warning signs".
        
            \begin{itemize}
            
                \item Any point beyond $\pm 3\sigma$.
                
                \item Nine consecutive points all above or all below $\mu$.
                
                \item Two of Three consecutive points beyond $\pm 2\sigma$.
                
            \end{itemize}
            
        \item Conversion to standard normal distribution: $z=\frac{x-\mu}{\sigma}$ or $x=\mu + z\sigma$. A $z$-score represents the number of standard deviations from normal an observation is.
        
        \item Using \texttt{normalcdf} to compute probabilities. Use $\pm 1 E 99$ for bounds $\pm\infty$.
        
        \item The Central Limit Theorem
        
        \end{enumerate}
        
    \newpage
    
    \item CHAPTER 7: Estimation (or Confidence Intervals)
    
        \begin{enumerate}
        
            \item General Philosophy of an $x$\% confidence interval: A \textbf{process} that produces an interval which contains the desired parameter $x$\% of the time.
            
            \item This \textbf{does not} mean given an $x$\% confidence interval, the chance the interval contains the parameter is $x$\%. This is like saying a 99\% accurate test (which means the text gets the \textbf{correct} diagnosis 99\% of the time) that says you have a disease means the probability of you \textbf{actually having the disease} is 99\%; which is a false, but common conclusion people make.
            
            \item The above point is a very common misconception and is often propagated. I myself am guilty of this. The good news however is that the confidence intervals we produce in this class actually have this additional property, so it is probably worth mentioning the fallacy, but not spending much time on it.
            
            \item CI types:
            
                \begin{itemize}
                
                    \item CI for $\mu$, $z$ or $t$-based.
                    
                    \item CI for $p$ a population proportion. Recall the requirements!
                    
                    \item CI for $\mu_1 - \mu_2$, $p_1-p_2$
                    
                    \item Mention the relevant functions.
                    
                \end{itemize}
                
        \end{enumerate}
        
    \item CHAPTER 8: Hypothesis Testing
    
        \begin{enumerate}
        
            \item Null Hypothesis: The assumption that a parameter is equal to some value.
            
            \item Alternate Hypothesis: The belief being ``tested", phrased that the parameter is different (in some fashion) from what is assumed.
            
            \item $p$-value and $\alpha$, the level of significance.
            
            \item Error types
            
            \item Test types -- completely determined by $H_1$.
            
            \item Reject $H_0$ when $p <= \alpha$. Phrasing a proper conclusion.
            
            \item Hypothesis test types:
            
                \begin{itemize}
                
                \item $z$ and $t$ tests
                
                \item Paired vs. Unpaired data. Be sure to state the null hypothesis is \textbf{always} $H_0: \mu = 0$ for such tests.
                
                \end{itemize}
                
        \end{enumerate}
        
\end{enumerate}

\newpage

%Friday after Exam 2

\section*{9.1 \& 9.2 Linear Correlation}

\begin{enumerate}

  \item The key ideas here are, of course, the correlation coefficient and the least squares line of best fit. This is frequently a topic that students have some familiarity with \ldots and some intuition for.
  
  \item If you are so compelled (inspired by) the actual formulas for the various pieces, then by all means, discuss. However, as for most things so far, the calculator can take care of it for them.
  
  \item I do think a brief conceptual discussion about ``least-squares" is based on is very much worthwhile. A discussion of how $r$ measures the ``goodness-of-fit" and how to interpret its value is.
  
  \item The key calculator function is \texttt{LinReg(a+bx)}.
  
    \begin{itemize}
    
        \item Note that there is also a \texttt{LinReg(ax+b)} that does precisely the same thing. HOWEVER, because we will be referring to the population slope with the letter $\beta$, the former is a better choice.
        
        \item Be sure to mention that we will \textbf{only} be using \texttt{LinReg(a+bx)} in this class to compute the line of best fit.
        
        \item In order to get the $r$ and $r^2$ values to display, the \texttt{DiagnosticsON} must be set. To do this, go to \texttt{Catalog} (which is located by \nth{2} + 0), select \texttt{DiagnosticsON} and push \texttt{Enter} twice.
        
    \end{itemize}
    
    \item A brief mention of the difference of interpolation and extrapolation would also be a good note.
    
    \item Mention the coefficient of determination and what it measures.
    
\end{enumerate}

\section*{9.3 Inference for Correlation}

\begin{enumerate}

    \item Note the notation for population parameters $\rho$, $\beta$, and  $y$.
    
    \item Most calculators should have \texttt{LinRegTTest} which simultaneously tests the sign of $\rho$ and $\beta$. Note that like null hypothesis in both cases is ``$= 0$".
    
    \item Now, the TI-84 will likely have \texttt{LinRegTInterval} to determine a confidence interval for the value of $\beta$, but TI-83 will not. There is a screencast to help them program a function to compute the interval.
    
    \item Further, neither TI-83 nor TI-84 will have a built-in function to compute a prediction interval (confidence interval) for y. (The TI-89 should.) The formula for E is not impossible to evaluate with the function, but it is certainly a bit of a pain. It may be good to present the formula so that they have a preview of what will be expected of them if they don’t program the function.
    
    \item There is a screencast on D2L and definitely mention this to them in class.
    
    \item One conceptual point to highlight, the closer $x$ is to the $\bar{x}$, the narrower the prediction interval is.

\end{enumerate}

\section*{10.2 Chi-Square: Goodness of Fit}

\begin{enumerate}

  \item Start with an overview of what ``goodness of fit" means. The null hypothesis is always that the population ``fits". The more deviant the data is from the expected distribution the worse the fit.
  
  \item Although this is a test that is supported by the TI, I like to spend some time analyzing the formula for chi-square and the distribution. It just so easy to see what it is measuring and why large test statistic values imply small P-value.
  
  \item Note that we are using a different distribution (than standard normal or Student’s t).
  
  \item Note, we have yet another measure of degrees of freedom.
  
  \item The key calculator function is $\chi^2$\texttt{GOF-Test}.
  
\end{enumerate}

\section*{10.5 ANOVA}

\begin{enumerate}

    \item My intent here is NOT to really get them to delve into the ``why" and ``how" the derivation of the sample F ratio, as I think that would require more time that we have. So, you can note that in the reading they will see a BUNCH of steps and intermediate computations, but they will not be responsible for understanding all those details for this class.
    
    \item Talk about the null and alternate hypotheses of the test.
    
    \item Talk about the sample F ratio is a measure of the variance BETWEEN populations versus the variance WITHIN each population. When there is significant variance BETWEEN, our F ratio will be big (we are removing the impact of the variance within each separate population and basically isolating the difference between populations).
    
    \item Note that we are using yet another distribution.
    
    \item Note that evidence supporting that there is a difference between the populations provides no direct evidence on which population might be the different one.
    
    \item The key calculator function is \texttt{ANOVA}.
    
\end{enumerate}

\end{document}
